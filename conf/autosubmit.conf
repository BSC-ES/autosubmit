[config]
# No need to change.
# Autosubmit version identifier
AUTOSUBMIT_VERSION =
# Maximum number of jobs to be waiting in the HPC queue
# Default = 3
MAXWAITINGJOBS = 3 
# Maximum number of jobs to be running at the same time at the HPC
# Default = 6
TOTALJOBS = 6 
# Initial value of submitted jobs
# Default = 0
ALREADYSUBMITTED = 0
# Time between connections to the HPC queue scheduler to poll already submitted jobs status
# Default = 10
SAFETYSLEEPTIME = 10
# Number of retrials if a job fails
# Default = 4
RETRIALS = 4
# Experiment identifier
EXPID =
# Verbose mode to see system output messages while running
VERBOSE = true
# Debug mode to see debug messages while running
# Default = false
DEBUG = false
# Where is Autosubmit default path to store files
ROOTDIR = /cfu/autosubmit/%(EXPID)s

# LOGGING(DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOGLEVEL = DEBUG

# Name of the logging file:
# Default = would be great to be able to pass the PID of the job through the
# name of the logfile --> THAT WILL BE POSSIBLE AT RUNTIME
LOGNAME = %(EXPID)s.log

# On the HPC = where are the jobs touching files, writing logs.
# Default ~/%(EXPID)s_LOG_DIR
HPCFILEDIR = ~/%(EXPID)s_LOG_DIR

# Is Autosubmit running remotely or locally:(with ssh or not)?
# Default = remote
RUNMODE = remote

# IF RUNMODE=Remote = default connection/transfer command:ssh, scp,rsync
# if key files,alias have to be set its here.

# Where is Autosubmit putting the touch files, scripts, temp files ect.
# Default  %(ROOTDIR)s/tmp/
AUTOFILEDIR = %(ROOTDIR)s/tmp/

# Where is Autosubmit reading the experiment definition file
# Default  %(ROOTDIR)s/conf/expdef_%(EXPID)s.conf
EXPDEFFILE = %(ROOTDIR)s/conf/expdef_%(EXPID)s.conf
# Where is Autosubmit reading the architecture definition file.
# Default  %(ROOTDIR)s/conf/archdef_%(EXPID)s.conf
ARCHDEFFILE = %(ROOTDIR)s/conf/archdef_%(EXPID)s.conf

# Autosubmit HEADER for remote jobs
AS-HEADER-REM=
# autosubmit header
 set -xuve
 job_name_ptrn=%SCRATCH_DIR%/%HPCPROJ%/%HPCUSER%/%EXPID%/LOG_%EXPID%/%JOBNAME%
 job_cmd_stamp=$(stat -c %Z $job_name_ptrn.cmd)
 job_start_time=$(date +%s)
 job_queue_time=$((job_start_time - job_cmd_stamp))

# Autosubmit TAILER for remote jobs
AS-TAILER-REM=
# autosubmit tailer
 job_end_time=$(date +%s)
 job_run_time=$((job_end_time - job_start_time))
 case $HPCARCH in
  ithaca)       errfile_created="TRUE"; errfile_ptrn="\.e" ;;
  marenostrum)  errfile_created="TRUE"; errfile_ptrn="\.err" ;;
  marenostrum3) errfile_created="TRUE"; errfile_ptrn="\.err" ;;
  ecmwf)        errfile_created="TRUE"; errfile_ptrn=".\err" ;;
  hector)       errfile_created="FALSE"; errfile_ptrn="\.e" ;;
  lindgren)     errfile_created="FALSE"; errfile_ptrn="\.e" ;;
  jaguar)       errfile_created="FALSE"; errfile_ptrn="\.e" ;;
  archer)       errfile_created="FALSE"; errfile_ptrn="\.e" ;;
  *) echo "!!! $HPCARCH is not valid platform !!!"; exit 1 ;;
 esac
 failed_jobs=0; failed_errfiles=""
 set +e; ls -1 ${job_name_ptrn}* | grep $errfile_ptrn
 if [[ $? -eq 0 ]]; then
  case $errfile_created in 
   TRUE)
    failed_jobs=$($(ls -1 ${job_name_ptrn}* | grep $errfile_ptrn | wc -l) - 1)
    failed_errfiles=$(ls -1 ${job_name_ptrn}* | grep $errfile_ptrn | head -n $failed_jobs)
   ;;
   FALSE)
    failed_jobs=$(ls -1 ${job_name_ptrn}* | grep $errfile_ptrn | wc -l)
    failed_errfiles=$(ls -1 ${job_name_ptrn}* | grep $errfile_ptrn)
   ;;
   *) "!!! $errfile_created is not valid errfile_created option !!!"; exit 1 ;;
  esac
 fi; set -e
 failed_jobs_qt=0; failed_jobs_rt=0
 for failed_errfile in $failed_errfiles; do
  failed_errfile_stamp=$(stat -c %Z $failed_errfile)
  failed_jobs_qt=$(failed_jobs_qt + $(grep "job_queue_time=" $failed_errfile | tail -n 1 | cut -d '=' -f 2))
  failed_jobs_rt=$(failed_jobs_rt + $((failied_errfile_stamp - $(grep "job_start_time=" $failed_errfile | tail -n 1 | cut -d '=' -f 2))
 done
 echo "$job_end_time $job_queue_time $job_run_time $failed_jobs $failed_jobs_qt $failed_jobs_rt" > ${job_name_ptrn}_COMPLETED

# Autosubmit HEADER for local jobs
AS-HEADER-LOC=
# autosubmit header
 set -xuve
 job_name_ptrn=/cfu/autosubmit/%EXPID%/tmp/LOG_%EXPID%/%JOBNAME%
 job_cmd_stamp=$(stat -c %Z $job_name_ptrn.cmd)
 job_start_time=$(date +%s)

# Autosubmit TAILER for local jobs
AS-TAILER-LOC=
# autosubmit tailer
 job_end_time=$(date +%s)
 job_run_time=$((job_end_time - job_start_time))
 errfile_ptrn="\.e"
 failed_jobs=0
 set +e; ls -1 ${job_name_ptrn}* | grep $errfile_ptrn
 if [[ $? -eq 0 ]]; then
  failed_jobs=$($(ls -1 ${job_name_ptrn}* | grep $errfile_ptrn | wc -l) - 1)
 fi
 echo "$job_end_time 0 $job_run_time $failed_jobs" > ${job_name_ptrn}_COMPLETED
